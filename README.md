# call-assistant

## High level architecture: 

        Incoming Call
                â†“
        CallScreeningService (Android)
                â†“ (15 sec timer)
        If user doesn't answer
                â†“
        Auto-answer call
                â†“
        Audio Stream (Mic + Speaker)
                â†“
        Speech-to-Text (Local)
                â†“
        Local LLM (Response generation)
                â†“
        Text-to-Speech (Local)
                â†“
        Caller hears AI voice


## File Structure:

                call-assistant/
                â”‚
                â”œâ”€â”€ assistant_core.py        # Entry point (Android will call this)
                â”œâ”€â”€ conversation.py          # Call flow + state machine
                â”œâ”€â”€ llm.py                   # Local LLM (TinyLlama / Phi)
                â”œâ”€â”€ stt_whisper_stream.py    # Streaming Whisper STT (optimized)
                â”œâ”€â”€ memory.py                # Call transcript storage
                â”‚
                â”œâ”€â”€ models/
                â”‚   â”œâ”€â”€ tinyllama.gguf       # LLM model, this needs to be downloaded locally | because this is llm model which is really has large fiel size, so stop complaning and read this ğŸ˜ 
                â”‚   â””â”€â”€ whisper/             # Whisper models | download this using `git clone https://huggingface.co/Systran/faster-whisper-base`
                â”‚
                â””â”€â”€ requirements.txt
